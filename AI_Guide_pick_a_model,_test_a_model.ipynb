{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP20mv/YOlOaImp6YAriDi9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyfallsin/MIECO/blob/main/AI_Guide_pick_a_model%2C_test_a_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Steps with Language Models\n",
        "\n",
        "Unlike other guides, this one is designed to:\n",
        "- not be tied to a closed-source / closed-data large language model (ex OpenAI, Anthropic)\n",
        "- broaden your perspective on what's already out there for any given task\n",
        "- create a data-led system for always identifying and using the state-of-the-art (SOTA) model for any particular task.\n",
        "\n",
        "We're going to hone in on \"text summarization\" as our first task."
      ],
      "metadata": {
        "id": "OPw-GjAas0m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So... why are we not using an existing LLM?\n",
        "\n",
        "Great question. Most available LLMs worth their salt can do many tasks, including summarization.\n",
        "\n",
        "However, many of them are not open, are trained on undisclosed data and exhibit biases. Responsible AI use require careful choices, and we're here to help you make them.\n",
        "\n",
        "Finally, most large LLMs require powerful GPU compute to use. While there are many models that you can use as a service, most of them cost money per API call. Unnecessary when some of the more common tasks can be done at good quality with already available open models and off-the-shelf hardware."
      ],
      "metadata": {
        "id": "gAihu4Qw-Gzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why do using open models matter?\n",
        "\n",
        "Over the last few decades, us engineers have been blessed with being able to onboard by starting with open source projects, and eventually shipping open source to production.\n",
        "\n",
        "However, recent developments in AI have changed this default state.\n",
        "\n",
        "Yes, there are many open models available. However, most guides don't discuss how to get started with them using simple steps."
      ],
      "metadata": {
        "id": "7e-c-RKd_pyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our First Project - Summarization\n",
        "\n",
        "We're going to:\n",
        "- Get some long documents to summarize.\n",
        "- Figure out how to summarize them using the current state-of-the-art open source models.\n",
        "- Write some code to do so."
      ],
      "metadata": {
        "id": "N6LEcWmCt6v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Where can I grab some documents?\n",
        "For simplicity's sake, let's grab a few HTML pages.\n",
        "\n",
        "Note that in the real world, you will likely have use other libraries to extract content for any particular file type."
      ],
      "metadata": {
        "id": "kcb9K3dLubjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we will import the `requests` library to grab webpages\n",
        "import requests\n",
        "\n",
        "# TODO: replace these URLs\n",
        "urls = ['https://blog.mozilla.org/en/mozilla/responsible-ai-challenge-winners/']\n",
        "html_pages = [requests.get(url).text for url in urls]"
      ],
      "metadata": {
        "id": "uHgg18k1t4sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's use the Python HTML parser BeautifulSoup to grab the body text of these pages"
      ],
      "metadata": {
        "id": "Buf0eQHo0msv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "page_content = []\n",
        "\n",
        "for html_page in html_pages:\n",
        "    soup = BeautifulSoup(html_page, 'html.parser')\n",
        "    if soup.body:\n",
        "        for tag in soup.body(['footer', 'div.footer']):\n",
        "          tag.decompose()\n",
        "        page_content.append(soup.body.get_text())\n",
        "\n",
        "print(page_content[0])"
      ],
      "metadata": {
        "id": "GEHyIa4h0tzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great. Now we're ready to start summarizing."
      ],
      "metadata": {
        "id": "W5Y9LBzfujnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What's next? A brief pause.\n",
        "\n",
        "The AI space is moving so fast that it requires a tremendous amount of catching up on scientific papers every week to understand the lay of the land.\n",
        "\n",
        "It's quite difficult for an engineer who is brand new to AI to:\n",
        "1. discover which open models are even out there\n",
        "2. of those, which models are appropriate for a particular task\n",
        "3. which benchmarks are used to evaluate the models\n",
        "4. which of those models are performing well based on evaluations\n",
        "5. of those models, which ones can actually run on available hardware\n",
        "\n",
        "For the journeyman engineer on a deadline, this is not tractable.\n"
      ],
      "metadata": {
        "id": "DM2n6byeDHss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do I select a summarization model?\n",
        "\n",
        "For now, we recommend [Huggingface](https://huggingface.co/models?pipeline_tag=summarization) and their large directory of open models broken down by task. This is a great starting point. Note that larger LLMs are also included in these lists, so we will have to filter.\n",
        "\n",
        "There are a lot of models available, many forks of existing models as well, and it's not entirely easy even to decide on three models to test out.\n",
        "\n",
        "We also don't know what any of these models are trained on. For example, a summarizer trained on news articles vs Reddit posts will perform better on news articles.\n",
        "\n",
        "We also don't know whether these models can run on available commodity hardware or require GPUs to run well.\n",
        "\n",
        "What we need is a set of metrics and benchmarks that we can use to do apples-to-apples comparisons of these models.\n",
        "\n",
        "So, the next step is to uncover how summarization models are compared against each other."
      ],
      "metadata": {
        "id": "oG-p4zhyJ35-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do I benchmark summarization models?"
      ],
      "metadata": {
        "id": "LJ0kYfaHYypn"
      }
    }
  ]
}