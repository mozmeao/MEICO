{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiMpRnn5qeRoHLzpAl8BY7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skyfallsin/MIECO/blob/main/AI_Guide_pick_a_model%2C_test_a_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Steps with Language Models\n",
        "\n",
        "Unlike other guides, this one is designed to:\n",
        "- not be tied to a closed-source / closed-data large language model (ex OpenAI, Anthropic)\n",
        "- broaden your perspective on what's already out there for any given task\n",
        "- create a data-led system for always identifying and using the state-of-the-art (SOTA) model for any particular task.\n",
        "\n",
        "We're going to hone in on \"text summarization\" as our first task."
      ],
      "metadata": {
        "id": "OPw-GjAas0m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## So... why are we not using an existing LLM?\n",
        "\n",
        "Great question. Most available LLMs worth their salt can do many tasks, including summarization.\n",
        "\n",
        "However, many of them are not open, are trained on undisclosed data and exhibit biases. Responsible AI use require careful choices, and we're here to help you make them.\n",
        "\n",
        "Finally, most large LLMs require powerful GPU compute to use. While there are many models that you can use as a service, most of them cost money per API call. Unnecessary when some of the more common tasks can be done at good quality with already available open models and off-the-shelf hardware."
      ],
      "metadata": {
        "id": "gAihu4Qw-Gzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why do using open models matter?\n",
        "\n",
        "Over the last few decades, engineers have been blessed with being able to onboard by starting with open source projects, and eventually shipping open source to production. This default state is now at risk.\n",
        "\n",
        "Yes, there are many open models available that do a great job. However, most guides don't discuss how to get started with them using simple steps and instead bias towards existing closed APIs.\n",
        "\n",
        "Funding is flowing to commercial AI projects, who have larger budgets than open source contributors to market their work, which inevitably leads to engineers starting with closed source projects and shipping expensive closed projects to production."
      ],
      "metadata": {
        "id": "7e-c-RKd_pyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Our First Project - Summarization\n",
        "\n",
        "We're going to:\n",
        "- Get some long documents to summarize.\n",
        "- Figure out how to summarize them using the current state-of-the-art open source models.\n",
        "- Write some code to do so."
      ],
      "metadata": {
        "id": "N6LEcWmCt6v1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Where can I grab some documents?\n",
        "For simplicity's sake, let's grab a few HTML pages.\n",
        "\n",
        "Note that in the real world, you will likely have use other libraries to extract content for any particular file type."
      ],
      "metadata": {
        "id": "kcb9K3dLubjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# first, we will import the `requests` library to grab webpages\n",
        "import requests\n",
        "\n",
        "# TODO: replace these URLs\n",
        "urls = ['https://blog.mozilla.org/en/mozilla/responsible-ai-challenge-winners/']\n",
        "html_pages = [requests.get(url).text for url in urls]"
      ],
      "metadata": {
        "id": "uHgg18k1t4sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's use the Python HTML parser BeautifulSoup to grab the body text of these pages"
      ],
      "metadata": {
        "id": "Buf0eQHo0msv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "page_content = []\n",
        "\n",
        "for html_page in html_pages:\n",
        "    soup = BeautifulSoup(html_page, 'html.parser')\n",
        "    if soup.body:\n",
        "        for tag in soup.body(['footer', 'div.footer']):\n",
        "          tag.decompose()\n",
        "        page_content.append(soup.body.get_text())\n",
        "\n",
        "print(page_content[0])"
      ],
      "metadata": {
        "id": "GEHyIa4h0tzL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great. Now we're ready to start summarizing."
      ],
      "metadata": {
        "id": "W5Y9LBzfujnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A brief pause for context.\n",
        "\n",
        "The AI space is moving so fast that it requires a tremendous amount of catching up on scientific papers every week to understand the lay of the land and the state of the art.\n",
        "\n",
        "It's quite difficult for an engineer who is brand new to AI to:\n",
        "* discover which open models are even out there\n",
        "* which models are appropriate for a particular task\n",
        "* which benchmarks are used to evaluate those models\n",
        "* which models are performing well based on evaluations\n",
        "* which models can actually run on available hardware\n",
        "\n",
        "For the journeyman engineer on a deadline, this is problematic. There's not much centralized discourse on working with open source AI models. Instead there are fragmented X (formerly Twitter) threads, random private groups and lots of word-of-mouth transfer.\n"
      ],
      "metadata": {
        "id": "DM2n6byeDHss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do I get a list of available open summarization models?\n",
        "\n",
        "For now, we recommend [Huggingface](https://huggingface.co/models?pipeline_tag=summarization) and their large directory of open models broken down by task. This is a great starting point. Note that larger LLMs are also included in these lists, so we will have to filter.\n",
        "\n",
        "In this huge list of summarization models, which ones do we choose?\n",
        "\n",
        "We don't know what any of these models are trained on. For example, a summarizer trained on news articles vs Reddit posts will perform better on news articles.\n",
        "\n",
        "What we need is a set of metrics and benchmarks that we can use to do apples-to-apples comparisons of these models."
      ],
      "metadata": {
        "id": "oG-p4zhyJ35-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How do I evaluate summarization models?\n",
        "\n",
        "These steps below can be used to evaluate any available model for any task. It requires hopping between a few sources of data for now, but we will be making this a lot easier moving forward.\n",
        "\n",
        "Steps:\n",
        "1. Find the most common datasets used to train models for summarization.\n",
        "2. Train these models"
      ],
      "metadata": {
        "id": "LJ0kYfaHYypn"
      }
    }
  ]
}